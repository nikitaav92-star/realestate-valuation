#!/usr/bin/env python3
"""–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å CIAN - –ø–æ—á–µ–º—É –Ω–µ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ."""

import json
import logging
import sys
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
LOGGER = logging.getLogger(__name__)

def analyze_original_script():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∏ –Ω–∞—Ö–æ–¥–∏—Ç –ø—Ä–æ–±–ª–µ–º—ã."""
    
    script_path = Path("scripts/test_captcha_strategy.py")
    
    if not script_path.exists():
        LOGGER.error("‚ùå –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    LOGGER.info("üîç –ê–ù–ê–õ–ò–ó –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ì–û –°–ö–†–ò–ü–¢–ê test_captcha_strategy.py")
    LOGGER.info("=" * 60)
    
    with open(script_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –ò—â–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –º–µ—Å—Ç–∞
    lines = content.split('\n')
    
    LOGGER.info("üìã –ù–ê–ô–î–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
    
    # 1. –ü–æ–∏—Å–∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    data_extraction_found = False
    for i, line in enumerate(lines, 1):
        if "query_selector_all" in line and "LinkArea" in line:
            LOGGER.info(f"   –°—Ç—Ä–æ–∫–∞ {i}: {line.strip()}")
            LOGGER.info(f"   ‚ùå –ü–†–û–ë–õ–ï–ú–ê: –¢–æ–ª—å–∫–æ –ø–æ–¥—Å—á–µ—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –ù–ï–¢ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö!")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏
            for j in range(i, min(i+5, len(lines))):
                if j < len(lines) and lines[j].strip():
                    LOGGER.info(f"      {j+1}: {lines[j].strip()}")
            data_extraction_found = True
    
    if not data_extraction_found:
        LOGGER.warning("   ‚ùå –ù–ï –ù–ê–ô–î–ï–ù–û: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    
    # 2. –ü–æ–∏—Å–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
    db_save_found = False
    for i, line in enumerate(lines, 1):
        if any(keyword in line.lower() for keyword in ["insert", "save", "database", "postgres"]):
            LOGGER.info(f"   –°—Ç—Ä–æ–∫–∞ {i}: {line.strip()}")
            db_save_found = True
    
    if not db_save_found:
        LOGGER.warning("   ‚ùå –ù–ï –ù–ê–ô–î–ï–ù–û: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
    
    # 3. –ü–æ–∏—Å–∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
    content_extraction_found = False
    for i, line in enumerate(lines, 1):
        if any(keyword in line.lower() for keyword in ["textcontent", "innerhtml", "evaluate", "extract"]):
            LOGGER.info(f"   –°—Ç—Ä–æ–∫–∞ {i}: {line.strip()}")
            content_extraction_found = True
    
    if not content_extraction_found:
        LOGGER.warning("   ‚ùå –ù–ï –ù–ê–ô–î–ï–ù–û: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    
    LOGGER.info("\nüéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:")
    LOGGER.info("   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç:")
    LOGGER.info("   ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ö–æ–¥–∏—Ç –∞–Ω—Ç–∏-–±–æ—Ç –∑–∞—â–∏—Ç—É")
    LOGGER.info("   ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã CIAN")
    LOGGER.info("   ‚úÖ –°—á–∏—Ç–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
    LOGGER.info("   ‚ùå –ù–ï –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    LOGGER.info("   ‚ùå –ù–ï —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")

def check_database_status():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    
    LOGGER.info("\nüóÑÔ∏è –°–¢–ê–¢–£–° –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
    LOGGER.info("=" * 60)
    
    try:
        import subprocess
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        result = subprocess.run([
            "docker", "exec", "realestate-postgres-1", "psql", 
            "-U", "realuser", "-d", "realdb", "-c", 
            "SELECT COUNT(*) as total_listings FROM listings;"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            count_line = result.stdout.strip().split('\n')[-2]
            count = count_line.strip()
            LOGGER.info(f"   üìä –ó–∞–ø–∏—Å–µ–π –≤ –ë–î: {count}")
            
            if int(count) <= 2:
                LOGGER.warning("   ‚ö†Ô∏è  –¢–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ë–î")
                LOGGER.warning("   ‚ùå –†–µ–∞–ª—å–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –ù–ï —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è")
        else:
            LOGGER.error(f"   ‚ùå –û—à–∏–±–∫–∞ –ë–î: {result.stderr}")
            
    except Exception as e:
        LOGGER.error(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ë–î: {e}")

def check_logs():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö."""
    
    LOGGER.info("\nüìã –ê–ù–ê–õ–ò–ó –õ–û–ì–û–í:")
    LOGGER.info("=" * 60)
    
    log_file = Path("logs/captcha_strategy.log")
    if not log_file.exists():
        LOGGER.warning("   ‚ùå –õ–æ–≥ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    with open(log_file, 'r') as f:
        lines = f.readlines()
    
    # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    extraction_mentions = 0
    for line in lines:
        if any(keyword in line.lower() for keyword in ["extract", "parse", "title", "price", "address"]):
            if "offers" not in line.lower() or "count" not in line.lower():
                extraction_mentions += 1
                if extraction_mentions <= 3:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3
                    LOGGER.info(f"   {line.strip()}")
    
    if extraction_mentions == 0:
        LOGGER.warning("   ‚ùå –í –ª–æ–≥–∞—Ö –ù–ï–¢ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
        LOGGER.warning("   ‚ùå –¢–æ–ª—å–∫–æ –ø–æ–¥—Å—á–µ—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –Ω–æ –ù–ï –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ")
    else:
        LOGGER.info(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ {extraction_mentions} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")

def create_fix_recommendations():
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é."""
    
    LOGGER.info("\nüõ†Ô∏è –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–†–ê–í–õ–ï–ù–ò–Æ:")
    LOGGER.info("=" * 60)
    
    recommendations = [
        "1. –ó–ê–ú–ï–ù–ò–¢–¨ –ø–æ–¥—Å—á–µ—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:",
        "   –ë–´–õ–û: offers = page.query_selector_all('[data-name=\"LinkArea\"]')",
        "   –î–û–õ–ñ–ù–û –ë–´–¢–¨: offers_data = page.evaluate('() => { /* –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö */ }')",
        "",
        "2. –î–û–ë–ê–í–ò–¢–¨ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ:",
        "   - title = card.querySelector('[data-mark=\"OfferTitle\"]').textContent",
        "   - price = card.querySelector('[data-mark=\"MainPrice\"]').textContent", 
        "   - address = card.querySelector('[data-mark=\"GeoLabel\"]').textContent",
        "",
        "3. –î–û–ë–ê–í–ò–¢–¨ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö:",
        "   - –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL",
        "   - INSERT –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è listings –∏ listing_prices",
        "   - –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤",
        "",
        "4. –ò–°–ü–†–ê–í–ò–¢–¨ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö:",
        "   - –ü–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω (—É–±—Ä–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã, ‚ÇΩ)",
        "   - –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–Ω–∞—Ç (—Å—Ç—É–¥–∏—è = 0)",
        "   - –ü–∞—Ä—Å–∏–Ω–≥ –ø–ª–æ—â–∞–¥–∏ (—É–±—Ä–∞—Ç—å –º¬≤)",
        "",
        "5. –î–û–ë–ê–í–ò–¢–¨ –≤–∞–ª–∏–¥–∞—Ü–∏—é:",
        "   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π",
        "   - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö",
        "   - –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞"
    ]
    
    for rec in recommendations:
        LOGGER.info(f"   {rec}")

def show_real_vs_fake_data():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∏ —Ñ–µ–π–∫–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏."""
    
    LOGGER.info("\nüîç –°–†–ê–í–ù–ï–ù–ò–ï: –†–ï–ê–õ–¨–ù–´–ï vs –§–ï–ô–ö–û–í–´–ï –î–ê–ù–ù–´–ï:")
    LOGGER.info("=" * 60)
    
    LOGGER.info("üìä –§–ï–ô–ö–û–í–´–ï –î–ê–ù–ù–´–ï (logs/demo_cian_data.json):")
    LOGGER.info("   ‚ùå ID: 1000000, 1000001, 1000002... (–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ)")
    LOGGER.info("   ‚ùå URL: https://www.cian.ru/sale/flat/1000000/ (–Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç)")
    LOGGER.info("   ‚ùå –ê–¥—Ä–µ—Å–∞: –ú–æ—Å–∫–≤–∞, –ê—Ä–±–∞—Ç, 15 (—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã)")
    LOGGER.info("   ‚ùå –¶–µ–Ω—ã: 8,786,145 ‚ÇΩ (—Å–ª—É—á–∞–π–Ω—ã–µ)")
    LOGGER.info("   ‚ùå AI –∞–Ω–∞–ª–∏–∑: '–ï–≤—Ä–æ—Ä–µ–º–æ–Ω—Ç (3/5)' (—Ñ–µ–π–∫–æ–≤—ã–π)")
    
    LOGGER.info("\n‚úÖ –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï (—á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å):")
    LOGGER.info("   ‚úÖ ID: 12345678, 87654321... (—Ä–µ–∞–ª—å–Ω—ã–µ ID —Å CIAN)")
    LOGGER.info("   ‚úÖ URL: https://www.cian.ru/sale/flat/12345678/ (—Ä–∞–±–æ—Ç–∞—é—â–∏–µ —Å—Å—ã–ª–∫–∏)")
    LOGGER.info("   ‚úÖ –ê–¥—Ä–µ—Å–∞: –ú–æ—Å–∫–≤–∞, —É–ª. –õ–µ–Ω–∏–Ω–∞, 45, –∫–≤. 12 (—Ä–µ–∞–ª—å–Ω—ã–µ)")
    LOGGER.info("   ‚úÖ –¶–µ–Ω—ã: 15 500 000 ‚ÇΩ (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ)")
    LOGGER.info("   ‚úÖ AI –∞–Ω–∞–ª–∏–∑: '–•–æ—Ä–æ—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –Ω—É–∂–µ–Ω –∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–º–æ–Ω—Ç'")

if __name__ == "__main__":
    LOGGER.info("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú–´ –° CIAN")
    LOGGER.info("=" * 60)
    
    analyze_original_script()
    check_database_status()
    check_logs()
    create_fix_recommendations()
    show_real_vs_fake_data()
    
    LOGGER.info("\nüéØ –ò–¢–û–ì–û–í–´–ô –í–´–í–û–î:")
    LOGGER.info("   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç test_captcha_strategy.py")
    LOGGER.info("   –£–°–ü–ï–®–ù–û –æ–±—Ö–æ–¥–∏—Ç –∞–Ω—Ç–∏-–±–æ—Ç –∑–∞—â–∏—Ç—É, –Ω–æ")
    LOGGER.info("   –ù–ï –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–π!")
    LOGGER.info("   ")
    LOGGER.info("   –î–µ–º–æ-–¥–∞–Ω–Ω—ã–µ - —ç—Ç–æ –ò–°–ö–£–°–°–¢–í–ï–ù–ù–û —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã,")
    LOGGER.info("   –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∏–µ –∫–∞–∫ –î–û–õ–ñ–ù–´ –≤—ã–≥–ª—è–¥–µ—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")

