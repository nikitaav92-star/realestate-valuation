#!/usr/bin/env python3
"""
–õ–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏-–ø–∞—Ä—Å–µ—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤/–∞–¥—Ä–µ—Å–æ–≤.

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
1. –ü–†–û–ö–°–ò = –¢–û–õ–¨–ö–û –î–õ–Ø COOKIES (—á–µ—Ä–µ–∑ get_cookies_with_proxy.py)
2. –ü–ê–†–°–ò–ù–ì = –í–°–ï–ì–î–ê –ë–ï–ó –ü–†–û–ö–°–ò (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ cookies)
3. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É: mapper, upsert, browser_fetcher
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
    # –ü–∞—Ä—Å–∏–Ω–≥ –î–º–∏—Ç—Ä–æ–≤—Å–∫–æ–≥–æ —Ä–∞–π–æ–Ω–∞
    python -m etl.collector_cian.local_parser --location dmitrov --pages 10

    # –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞
    python -m etl.collector_cian.local_parser --subdomain yahroma --pages 5

    # –ö–∞—Å—Ç–æ–º–Ω—ã–π URL
    python -m etl.collector_cian.local_parser --url "https://www.cian.ru/cat.php?..." --pages 3
"""
from __future__ import annotations

import argparse
import logging
import os
import re
import sys
import time
from pathlib import Path
from typing import Any, Dict, List, Optional
from urllib.parse import urlencode

from playwright.sync_api import sync_playwright, Page

# Add project root to path
sys.path.insert(0, str(Path(__file__).resolve().parents[2]))

from etl.collector_cian.browser_fetcher import (
    _parse_offers_from_html,
    clean_address_text,
)
from etl.collector_cian.mapper import to_listing, to_price
from etl.upsert import get_db_connection, upsert_listing, upsert_price_if_changed

LOGGER = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–∫–∞—Ü–∏–π
# –ö–ª—é—á = –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è, –∑–Ω–∞—á–µ–Ω–∏–µ = dict —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
LOCATIONS = {
    "dmitrov": {
        "name": "–î–º–∏—Ç—Ä–æ–≤—Å–∫–∏–π —Ä–∞–π–æ–Ω –ú–û",
        "subdomain": None,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º www.cian.ru
        "region": 4593,     # –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å
        "address_filters": ["–¥–º–∏—Ç—Ä–æ–≤", "—è—Ö—Ä–æ–º", "–∏–∫—à–∞", "–Ω–µ–∫—Ä–∞—Å–æ–≤", "–¥–µ–¥–µ–Ω–µ–≤", "—Ä–æ–≥–∞—á—ë–≤"],
        "description": "–î–º–∏—Ç—Ä–æ–≤, –Ø—Ö—Ä–æ–º–∞, –ò–∫—à–∞ –∏ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏",
    },
    "yahroma": {
        "name": "–Ø—Ö—Ä–æ–º–∞",
        "subdomain": "yahroma",  # yahroma.cian.ru
        "region": None,
        "address_filters": ["—è—Ö—Ä–æ–º"],
        "description": "–ì–æ—Ä–æ–¥ –Ø—Ö—Ä–æ–º–∞",
    },
    "serpuhov": {
        "name": "–°–µ—Ä–ø—É—Ö–æ–≤",
        "subdomain": "serpuhov",
        "region": None,
        "address_filters": ["—Å–µ—Ä–ø—É—Ö–æ–≤"],
        "description": "–°–µ—Ä–ø—É—Ö–æ–≤ –∏ —Ä–∞–π–æ–Ω",
    },
    "kolomna": {
        "name": "–ö–æ–ª–æ–º–Ω–∞",
        "subdomain": "kolomna",
        "region": None,
        "address_filters": ["–∫–æ–ª–æ–º–Ω"],
        "description": "–ö–æ–ª–æ–º–Ω–∞ –∏ —Ä–∞–π–æ–Ω",
    },
}

DEFAULT_STORAGE_PATH = Path(__file__).resolve().parents[2] / "config/cian_browser_state.json"


def build_local_url(
    location_key: str = None,
    subdomain: str = None,
    region: int = None,
    page: int = 1,
    deal_type: str = "sale",
    offer_type: str = "flat",
    secondary_only: bool = True,
    rooms: List[int] = None,
) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç URL –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞.

    Parameters
    ----------
    location_key : str
        –ö–ª—é—á –∏–∑ LOCATIONS dict
    subdomain : str
        –ü–æ–¥–¥–æ–º–µ–Ω –¶–ò–ê–ù (dmitrov, yahroma, etc.)
    region : int
        ID —Ä–µ–≥–∏–æ–Ω–∞ (4593 = –ú–û)
    page : int
        –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    """
    query = {
        "deal_type": deal_type,
        "engine_version": 2,
        "offer_type": offer_type,
        "sort": "creation_date_desc",
        "p": page,
    }

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—ã–π –¥–æ–º–µ–Ω
    base_domain = "www.cian.ru"

    if location_key and location_key in LOCATIONS:
        loc = LOCATIONS[location_key]
        if loc.get("subdomain"):
            base_domain = f"{loc['subdomain']}.cian.ru"
        if loc.get("region"):
            query["region"] = loc["region"]
    elif subdomain:
        base_domain = f"{subdomain}.cian.ru"

    if region:
        query["region"] = region

    # –í—Ç–æ—Ä–∏—á–∫–∞
    if secondary_only:
        query["object_type[0]"] = 1

    # –ö–æ–º–Ω–∞—Ç—ã
    if rooms:
        for r in rooms:
            query[f"room{r}"] = 1
    else:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ –∫–æ–º–Ω–∞—Ç—ã
        for r in [0, 1, 2, 3, 4, 5, 6]:
            query[f"room{r}"] = 1

    params = urlencode(query, doseq=True)
    return f"https://{base_domain}/cat.php?{params}"


def parse_page(page: Page, url: str) -> List[Dict[str, Any]]:
    """
    –ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç offers.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç _parse_offers_from_html –∏–∑ browser_fetcher.
    """
    try:
        response = page.goto(url, wait_until="domcontentloaded", timeout=30000)

        if not response:
            LOGGER.warning(f"–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç {url}")
            return []

        if response.status == 429:
            LOGGER.error(f"‚ùå Rate limit (429)! –ù—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å cookies.")
            LOGGER.info("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python config/get_cookies_with_proxy.py")
            return []

        if response.status >= 400:
            LOGGER.warning(f"HTTP {response.status} –¥–ª—è {url}")
            return []

        # –ñ–¥—ë–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        page.wait_for_timeout(2000)

        # –ü–∞—Ä—Å–∏–º —á–µ—Ä–µ–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é
        offers = _parse_offers_from_html(page)
        return offers

    except Exception as e:
        LOGGER.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
        return []


def filter_by_address(offers: List[Dict], address_filters: List[str]) -> List[Dict]:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç offers –ø–æ –∞–¥—Ä–µ—Å—É.

    Parameters
    ----------
    offers : list
        –°–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    address_filters : list
        –°–ø–∏—Å–æ–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∞–¥—Ä–µ—Å–µ (lowercase)
    """
    if not address_filters:
        return offers

    filtered = []
    for offer in offers:
        address = (offer.get("address") or "").lower()
        if any(f in address for f in address_filters):
            filtered.append(offer)

    return filtered


def save_to_db(offers: List[Dict]) -> tuple[int, int]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç offers –≤ –ë–î —á–µ—Ä–µ–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π upsert.

    Returns
    -------
    tuple
        (saved_count, price_updates_count)
    """
    conn = get_db_connection()
    saved = 0
    prices = 0

    try:
        for offer in offers:
            try:
                listing = to_listing(offer)
                price = to_price(offer)

                upsert_listing(conn, listing)
                saved += 1

                if upsert_price_if_changed(conn, listing.id, price.price):
                    prices += 1

            except ValueError as e:
                # Skip newbuildings, shares, etc.
                LOGGER.debug(f"–ü—Ä–æ–ø—É—Å–∫: {e}")
                continue
            except Exception as e:
                LOGGER.warning(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è offer: {e}")
                continue

        conn.commit()

    except Exception as e:
        conn.rollback()
        LOGGER.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
    finally:
        conn.close()

    return saved, prices


def collect_local(
    location_key: str = None,
    subdomain: str = None,
    custom_url: str = None,
    pages: int = 10,
    address_filters: List[str] = None,
    save: bool = True,
) -> List[Dict]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞.

    –í–ê–ñ–ù–û: –†–∞–±–æ—Ç–∞–µ—Ç –ë–ï–ó –ü–†–û–ö–°–ò, –∏—Å–ø–æ–ª—å–∑—É—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ cookies!

    Parameters
    ----------
    location_key : str
        –ö–ª—é—á –ª–æ–∫–∞—Ü–∏–∏ –∏–∑ LOCATIONS
    subdomain : str
        –ü–æ–¥–¥–æ–º–µ–Ω –¶–ò–ê–ù
    custom_url : str
        –ö–∞—Å—Ç–æ–º–Ω—ã–π URL (–±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ page)
    pages : int
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    address_filters : list
        –§–∏–ª—å—Ç—Ä—ã –∞–¥—Ä–µ—Å–æ–≤
    save : bool
        –°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –ë–î

    Returns
    -------
    list
        –í—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ offers
    """
    storage_path = Path(os.getenv("CIAN_STORAGE_STATE", str(DEFAULT_STORAGE_PATH)))

    if not storage_path.exists():
        LOGGER.error(f"‚ùå Cookies –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {storage_path}")
        LOGGER.info("üí° –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏—Ç–µ cookies: python config/get_cookies_with_proxy.py")
        return []

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç cookies
    age_hours = (time.time() - storage_path.stat().st_mtime) / 3600
    if age_hours > 24:
        LOGGER.warning(f"‚ö†Ô∏è Cookies —É—Å—Ç–∞—Ä–µ–ª–∏ ({age_hours:.1f} —á–∞—Å–æ–≤)")
        LOGGER.info("üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–∏—Ç—å: python config/get_cookies_with_proxy.py")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –∞–¥—Ä–µ—Å–æ–≤
    if address_filters is None and location_key and location_key in LOCATIONS:
        address_filters = LOCATIONS[location_key].get("address_filters", [])

    location_name = "Custom"
    if location_key and location_key in LOCATIONS:
        location_name = LOCATIONS[location_key]["name"]
    elif subdomain:
        location_name = subdomain.capitalize()

    LOGGER.info("=" * 60)
    LOGGER.info(f"üè† –õ–æ–∫–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä: {location_name}")
    LOGGER.info("=" * 60)
    LOGGER.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü: {pages}")
    LOGGER.info(f"üîç –§–∏–ª—å—Ç—Ä—ã –∞–¥—Ä–µ—Å–æ–≤: {address_filters or '–Ω–µ—Ç'}")
    LOGGER.info(f"üìÇ Cookies: {storage_path}")
    LOGGER.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î: {'–¥–∞' if save else '–Ω–µ—Ç'}")
    LOGGER.info("")

    all_offers = []

    with sync_playwright() as p:
        # –í–ê–ñ–ù–û: –ó–∞–ø—É—Å–∫ –ë–ï–ó –ü–†–û–ö–°–ò!
        LOGGER.info("üîì –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞ –ë–ï–ó –ü–†–û–ö–°–ò (–∏—Å–ø–æ–ª—å–∑—É–µ–º cookies)")
        browser = p.chromium.launch(headless=True)

        context = browser.new_context(
            storage_state=str(storage_path),
            user_agent=(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                "(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
            ),
        )
        context.add_init_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined});"
        )

        page = context.new_page()

        for page_num in range(1, pages + 1):
            # –°—Ç—Ä–æ–∏–º URL
            if custom_url:
                url = custom_url + f"&p={page_num}" if "?" in custom_url else custom_url + f"?p={page_num}"
            else:
                url = build_local_url(
                    location_key=location_key,
                    subdomain=subdomain,
                    page=page_num,
                )

            LOGGER.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{pages}")

            offers = parse_page(page, url)

            if not offers:
                LOGGER.info(f"  ‚ö†Ô∏è –ù–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏–π, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è")
                break

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∞–¥—Ä–µ—Å—É
            if address_filters:
                filtered = filter_by_address(offers, address_filters)
                LOGGER.info(f"  ‚úì –ù–∞–π–¥–µ–Ω–æ {len(offers)} ‚Üí –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered)}")
                all_offers.extend(filtered)

                # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ
                for o in filtered[:3]:
                    addr = o.get("address", "N/A")[:50]
                    price = o.get("price", 0)
                    LOGGER.info(f"    ‚Ä¢ {addr} - {price:,} ‚ÇΩ")
            else:
                all_offers.extend(offers)
                LOGGER.info(f"  ‚úì –ù–∞–π–¥–µ–Ω–æ {len(offers)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
            time.sleep(2)

        browser.close()

    LOGGER.info("")
    LOGGER.info("=" * 60)
    LOGGER.info(f"üìä –ò–¢–û–ì–û: {len(all_offers)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")

    if save and all_offers:
        saved, prices = save_to_db(all_offers)
        LOGGER.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {saved} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤, {prices} –Ω–æ–≤—ã—Ö —Ü–µ–Ω")

    LOGGER.info("=" * 60)

    return all_offers


def main():
    """CLI entry point."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s %(message)s"
    )

    parser = argparse.ArgumentParser(
        description="–õ–æ–∫–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¶–ò–ê–ù –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ (–ë–ï–ó –ü–†–û–ö–°–ò)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  python -m etl.collector_cian.local_parser --location dmitrov --pages 10
  python -m etl.collector_cian.local_parser --subdomain yahroma --pages 5
  python -m etl.collector_cian.local_parser --url "https://www.cian.ru/cat.php?..." --pages 3

–î–æ—Å—Ç—É–ø–Ω—ã–µ –ª–æ–∫–∞—Ü–∏–∏:
""" + "\n".join(f"  {k}: {v['description']}" for k, v in LOCATIONS.items())
    )

    parser.add_argument(
        "--location", "-l",
        choices=list(LOCATIONS.keys()),
        help="–ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –ª–æ–∫–∞—Ü–∏—è",
    )
    parser.add_argument(
        "--subdomain", "-s",
        help="–ü–æ–¥–¥–æ–º–µ–Ω –¶–ò–ê–ù (dmitrov, yahroma, etc.)",
    )
    parser.add_argument(
        "--url", "-u",
        help="–ö–∞—Å—Ç–æ–º–Ω—ã–π URL (–±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ page)",
    )
    parser.add_argument(
        "--pages", "-p",
        type=int,
        default=10,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü (default: 10)",
    )
    parser.add_argument(
        "--filter", "-f",
        action="append",
        dest="filters",
        help="–§–∏–ª—å—Ç—Ä –ø–æ –∞–¥—Ä–µ—Å—É (–º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ)",
    )
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –ë–î",
    )
    parser.add_argument(
        "--list-locations",
        action="store_true",
        help="–ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ª–æ–∫–∞—Ü–∏–∏",
    )

    args = parser.parse_args()

    if args.list_locations:
        print("\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –ª–æ–∫–∞—Ü–∏–∏:")
        print("=" * 50)
        for key, loc in LOCATIONS.items():
            print(f"  {key:15} - {loc['description']}")
            if loc.get("subdomain"):
                print(f"                   ‚Üí {loc['subdomain']}.cian.ru")
            if loc.get("address_filters"):
                print(f"                   ‚Üí —Ñ–∏–ª—å—Ç—Ä—ã: {', '.join(loc['address_filters'])}")
        print()
        return

    if not args.location and not args.subdomain and not args.url:
        parser.error("–£–∫–∞–∂–∏—Ç–µ --location, --subdomain –∏–ª–∏ --url")

    offers = collect_local(
        location_key=args.location,
        subdomain=args.subdomain,
        custom_url=args.url,
        pages=args.pages,
        address_filters=args.filters,
        save=not args.no_save,
    )

    LOGGER.info(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ–±—Ä–∞–Ω–æ {len(offers)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")


if __name__ == "__main__":
    main()
